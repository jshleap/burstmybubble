{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "comet_cell_id": "67e0ded42536e"
   },
   "source": [
    "# BurstMyBubble (BMB) exploration of training data\n",
    "\n",
    "The data used here can be found in [convote](http://www.cs.cornell.edu/home/llee/data/convote.html) from Cornell university. For the purpose of this app, we used the stage_one set in convote:\n",
    "\n",
    ">\"data_stage_one\" was used to identify by-name references to\n",
    "  train our agreement classifier, which acts on such references.  All\n",
    "  references in this dataset are annotated with a special set of\n",
    "  characters of the form \"xz1111111\", where 1111111 is replaced by a\n",
    "  seven-digit code indicating the House Member who we determined to be\n",
    "  the target of the reference.  The first six digits of the code\n",
    "  matches the index used to label the target Member's speech segments,\n",
    "  (see description of our individual-file-naming convention, below).  The\n",
    "  seventh digit is a relic from early experiments and was not used in\n",
    "  our final study.\n",
    "  \n",
    "This notebook will explore the development set to test the implementation of **BMB**. For this notebook to work you will have to untar `tar -xzvf convote_v1.1.tar.gz` in the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comet_cell_id": "0eb9791f21364"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "stop_words= stopwords.words(\"english\")\n",
    "data_path = '../data/convote_v1.1/data_stage_one/test_set'\n",
    "files = glob(os.path.join(data_path, '*.txt'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatize = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def frequency_explorer(tokens, title):\n",
    "    \"\"\"\n",
    "    This function tokenize it and plots the frequency of a text string\n",
    "    \"\"\"\n",
    "    tokens = [lemmatize.lemmatize(x) for x in tokens]\n",
    "    fdist = FreqDist(tokens)\n",
    "    print(fdist)\n",
    "    print(title)\n",
    "    fdist.plot(30,cumulative=False)\n",
    "    plt.show()\n",
    "\n",
    "def opennfilter(filename):\n",
    "    \"\"\"\n",
    "    Reads a file, tokenize it, filter stopwords, and returns a list of strings of cleaned text\n",
    "    \"\"\"\n",
    "    # get label based on the filename structure ###_@@@@@@_%%%%$$$_PMV.txt, where p is the party\n",
    "    party = filename[:filename.rfind('.txt')].split('_')[-1][0]\n",
    "    with open(filename) as text:\n",
    "        tokens = tokenizer.tokenize(text.read())\n",
    "        tokens = [lemmatize.lemmatize(x) for x in tokens]\n",
    "        filtered_sent = ' '.join([w for w in words if w not in stop_words])\n",
    "    return party, filtered_sent\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comet_cell_id": "02b405075014d"
   },
   "outputs": [],
   "source": [
    "text = open(files[0]).read()\n",
    "words = tokenizer.tokenize(text)\n",
    "frequency_explorer(words, 'Words from %s' % files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comet_cell_id": "950ce1b3ec2ba"
   },
   "outputs": [],
   "source": [
    "text = open(files[3]).read()\n",
    "words = tokenizer.tokenize(text)\n",
    "frequency_explorer(words, 'Words from %s' % files[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comet_cell_id": "d2c6cf98b1342"
   },
   "outputs": [],
   "source": [
    "text = open(files[3]).read()\n",
    "words = tokenizer.tokenize(text)\n",
    "filtered_sent3 = [w for w in words if w not in stop_words]\n",
    "frequency_explorer(filtered_sent3, 'Filtered Words from %s' % files[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comet_cell_id": "2be733783be27"
   },
   "outputs": [],
   "source": [
    "text = open(files[0]).read()\n",
    "words = tokenizer.tokenize(text)\n",
    "filtered_sent0 = [w for w in words if w not in stop_words]\n",
    "frequency_explorer(filtered_sent0, 'Filtered Words from %s' % files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comet_cell_id": "e54a86adef5ad"
   },
   "outputs": [],
   "source": [
    "docs = [(filename[:filename.rfind('.txt')].split('_')[-1][0], open(filename).read().strip()) for filename in files]\n",
    "labels, sentences = zip(*docs)\n",
    "labels = np.array(labels)\n",
    "cv = CountVectorizer(lowercase=True, stop_words='english', ngram_range = (1,5), tokenizer = tokenizer.tokenize)\n",
    "text_counts= cv.fit_transform(sentences)\n",
    "df1 = pd.DataFrame(text_counts.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comet_cell_id": "87ebcfc543b26"
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comet_cell_id": "d534927d65a85"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comet_cell_id": "dbf99986b819a"
   },
   "outputs": [],
   "source": [
    "colors = ['navy', 'crimson']\n",
    "plt.figure(figsize=(8, 8))\n",
    "for color, i, target_name in zip(colors, ['D', 'R'], labels):\n",
    "        plt.scatter(X_pca[labels == i, 0], X_pca[labels == i, 1], color=color, lw=1, label=target_name)\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comet_cell_id": "ebabb06012051"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "comet_paths": [],
  "comet_tracking": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
